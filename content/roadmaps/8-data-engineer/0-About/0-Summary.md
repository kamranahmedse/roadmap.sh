# Become a Data Engineer
First of all, it is important to note that starting with concepts can help a lot in your progress. On the other hand, if you want to get started with pratice, all you need is know SQL and some databases (one of your choice).

## Basic for everything
- **Version Control Systems and Git:** version control systems allow you to track changes to your codebase/files over time.
- **Shell script/bash:** used on a large scale for task scheduling and automation
- **SSH:** remote acess
- **HTTP/HTTPS:** you will use this knowledge it when you need to get data from APIs or others web endpoints
- **API:** for making and use
- **SQL:** used in absolutely every step
- **Docker:** out your data, apis and other in containers for build and run in everywhere
- **Kubernets:** for orchestration your containers
- **IaC/IaaS:** infraestructure and service is code now

## Programming Languages and Data
Some programming languages are used in data world, some for analysis, others for processing.
- Python
- R
- C++
- Scala

## Concepts
Some important concepts about data modeling, analytical repositories and big data
- OLTP and OLAP
- Star Schema
- Data Warehouses
- Data Lakes
- Data Catalog
- Data Pipelines
- Facts and Dimensions

## Databases
Knowledge of databases guides you to choose the best for your Big Data project, considering which one is best suited in each scenario. 
- Dremio
- RDBMS
- Document DB
- In-Memory DB

## ETL and ELT
ETL and ELT are two of the most popular methods of collecting data from multiple sources and storing it in a data warehouse that can be accessed by all users in an organization
- Apache Airflow
- Apache Nifi
- Pentaho

## Data Processing
Parallel processing of big data was first realized by data partitioning technique in database systems and ETL tools. Once a dataset is partitioned logically, each partition can be processed in parallel.
- Apache Kafka
- Apache Hadoop
- Apache Spark
- Apache Sqoop